{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3652ff0-3525-4ed8-a3e3-d8c866a2a245",
   "metadata": {},
   "source": [
    "LEARNING PYTROCH FOR DEEPLEARNING BY: https://www.youtube.com/watch?v=LyJtbe__2i0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab826c2-1922-4f0b-b6bf-310739c9c02e",
   "metadata": {},
   "source": [
    "Importing tensorflow and checking how many GPUs are working at the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d57aa-9992-4609-9ac9-40b670a20e6a",
   "metadata": {},
   "source": [
    "## 00. Pytorch Fundamentals\n",
    "Resources Notebook: https://www.learnpytorch.io/\n",
    "<br> if you have a question or Git code: https://github.com/mrdbourke/pytorch-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae81d3f-73ba-4aea-b003-8f6f41902c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47715872-da77-449e-895a-55ffd51e55f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun  7 03:11:41 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.07                 Driver Version: 566.07         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   49C    P8              2W /   80W |    1354MiB /   8188MiB |      3%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A       532    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A      2580    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A      3620    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      6768    C+G   ...1efjmfn5c\\Build\\Plugins\\mpv\\mpv.exe      N/A      |\n",
      "|    0   N/A  N/A      9260    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A      9724    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14064    C+G   ...pdnekdrzrea0\\XboxGameBarSpotify.exe      N/A      |\n",
      "|    0   N/A  N/A     16264    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     19072    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19516    C+G   ...4__8wekyb3d8bbwe\\EdgeGameAssist.exe      N/A      |\n",
      "|    0   N/A  N/A     20420    C+G   ...on\\136.0.3240.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     21152    C+G   ...1efjmfn5c\\Build\\Plugins\\mpv\\mpv.exe      N/A      |\n",
      "|    0   N/A  N/A     22388    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     22492    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     23356    C+G   ...ram Files (x86)\\AnyDesk\\AnyDesk.exe      N/A      |\n",
      "|    0   N/A  N/A     28472    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     28628    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     30556    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     31324    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     32500    C+G   ...x64__swvc1efjmfn5c\\Build\\Lively.exe      N/A      |\n",
      "|    0   N/A  N/A     32604    C+G   ...on\\136.0.3240.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     33084    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     33092    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A     34484    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     36756    C+G   ..._x64__cw5n1h2txyewy\\WidgetBoard.exe      N/A      |\n",
      "|    0   N/A  N/A     38880    C+G   ...__8wekyb3d8bbwe\\Microsoft.Notes.exe      N/A      |\n",
      "|    0   N/A  N/A     39524    C+G   ...ecurityApp\\MicrosoftSecurityApp.exe      N/A      |\n",
      "|    0   N/A  N/A     39992    C+G   ...ve\\Discord\\app-1.0.9194\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     40552    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091027e7-bb65-4553-8317-94d113cc5152",
   "metadata": {},
   "source": [
    "## INTRODUCTION TO TENSORS\n",
    "### Creating TENSORS \n",
    "pytorch tensors are created using torch.Tensor() = https://docs.pytorch.org/docs/stable/tensors.html#data-types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47cda35-80a7-4a6e-a9cb-adbbfdfff9a7",
   "metadata": {},
   "source": [
    "### Scalar Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4114ee5-da71-4ab2-b364-4cdaf13571b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)  # way to create scalar tensor\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab1f1607-84e9-40da-9735-433088aad84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim # to check the dimension \"We know a scalar is no dimesional number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2fcd206-69ac-4118-9c5d-907f7d666dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as python integer\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd5255-de1b-4d4a-b0f0-2c218fd4bb87",
   "metadata": {},
   "source": [
    "### Vector Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "259565f9-4234-4cfb-938f-3d5d1be85a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectors\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a30a9814-ec68-4882-bdba-68c5c917a984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d021fa82-39f4-4583-b178-a95d59246d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc769444-49e9-4789-8a4c-0f7b6430e509",
   "metadata": {},
   "source": [
    "### MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42095d61-c603-4d14-af70-ebaaf3f75e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 9],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix = torch.tensor([[8,9],[2,3]])\n",
    "Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4f0f20a-891f-4c2e-a953-db15fab2b10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "751995b0-05b7-47ca-8656-07ef5044db50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eae484d-0c05-4e6d-9252-bd3f644016bf",
   "metadata": {},
   "source": [
    "### TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "701a6b05-5339-4f12-9440-7cf7851c2b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1,2,3],[4,5,6],[7,8,9],[10,11,12]]])   \n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2c4de6f-8071-4c6e-b7de-7de48e51b983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a38496b0-e308-4e9c-99b4-7275a1fa9faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a228fdd-01ca-4813-9a46-8a1678392ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]  # If you will write TENSOR[1] it will give an error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8c90909-586a-4b6e-bfcc-7e6637deee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tensor with multiple batches\n",
    "TENSOR1 = torch.tensor([[[1,2,3,4],[3,4,5,4],[5,6,7,4]],\n",
    "                        [[7,8,9,4],[9,8,7,4],[6,5,4,4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd00df00-ac11-4f07-8d2b-0d7801d03f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR1.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a915cd04-25ab-462b-9b05-dfa14eaf1c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a757134f-e745-421f-abe7-0b9bf9761b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [3, 4, 5, 4],\n",
      "        [5, 6, 7, 4]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[7, 8, 9, 4],\n",
       "        [9, 8, 7, 4],\n",
       "        [6, 5, 4, 4]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(TENSOR1[0])\n",
    "\n",
    "TENSOR1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80c80b-095c-4abb-adb2-7baed4ba416d",
   "metadata": {},
   "source": [
    "### RANDOM TENSORS\n",
    "\n",
    "Why random tensor ?\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "<br> Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f42d364b-ad22-4e9f-a626-0617c9f92f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3424, 0.8233, 0.3077, 0.5862, 0.2074],\n",
       "         [0.8556, 0.3955, 0.6724, 0.6033, 0.3368],\n",
       "         [0.1171, 0.6754, 0.9167, 0.6777, 0.6548],\n",
       "         [0.8525, 0.0119, 0.3297, 0.1421, 0.8200],\n",
       "         [0.7010, 0.2348, 0.0537, 0.7801, 0.3419],\n",
       "         [0.6140, 0.4917, 0.3753, 0.9215, 0.5801]],\n",
       "\n",
       "        [[0.0820, 0.1169, 0.7622, 0.5965, 0.1094],\n",
       "         [0.0424, 0.0725, 0.0491, 0.9098, 0.8638],\n",
       "         [0.5681, 0.1167, 0.6110, 0.3409, 0.1904],\n",
       "         [0.7998, 0.5074, 0.7396, 0.7582, 0.4687],\n",
       "         [0.0404, 0.4601, 0.7587, 0.1023, 0.8922],\n",
       "         [0.5180, 0.8615, 0.2620, 0.0298, 0.3325]],\n",
       "\n",
       "        [[0.3248, 0.3786, 0.2839, 0.6122, 0.0854],\n",
       "         [0.7689, 0.7025, 0.1905, 0.1943, 0.3201],\n",
       "         [0.2655, 0.7021, 0.8276, 0.6921, 0.5392],\n",
       "         [0.6367, 0.7222, 0.3992, 0.8877, 0.7127],\n",
       "         [0.6475, 0.5381, 0.7487, 0.5572, 0.7693],\n",
       "         [0.0382, 0.4027, 0.0830, 0.5077, 0.9076]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random tensor of size(3,4)\n",
    "random_tensor = torch.rand(3,6,5) \n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d41d3f1a-c5cb-4e89-b742-2ccf403a760a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa6f6f32-09ff-4c1e-872b-7b7cd751c4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3424, 0.8233, 0.3077, 0.5862, 0.2074],\n",
       "        [0.8556, 0.3955, 0.6724, 0.6033, 0.3368],\n",
       "        [0.1171, 0.6754, 0.9167, 0.6777, 0.6548],\n",
       "        [0.8525, 0.0119, 0.3297, 0.1421, 0.8200],\n",
       "        [0.7010, 0.2348, 0.0537, 0.7801, 0.3419],\n",
       "        [0.6140, 0.4917, 0.3753, 0.9215, 0.5801]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d439c9b5-bce1-4812-95c0-eeef2442ffc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5a86c00-8225-4c39-9105-3eca41f08aaf",
   "metadata": {},
   "source": [
    "# Creating a random tensor with a similar shape to an image tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df66d4ad-6d04-4e43-8695-0a7c8dddd65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_tensor = torch.rand(size=(244,244,3)) # height, width , color channel (R,G,B)\n",
    "# random_image_tensor = torch.rand(244,244,3)  can be written as this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68ce046d-5236-493e-92fd-a7cd448deab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([244, 244, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d937e358-a8ba-4949-8f7d-bd3970c71d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a754adcf-ed77-4e3b-ab8b-9040401e1b21",
   "metadata": {},
   "source": [
    "### Tensors of zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "489e033e-b4cd-4d9d-9b81-465b6207bf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.Size([3, 4]),\n",
       " 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor with zeros\n",
    "zero_tensor = torch.zeros(3,4)\n",
    "zero_tensor, zero_tensor.shape, zero_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "263edc1e-997f-40c0-aa62-f91f869b4e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all ones\n",
    "one_tensor = torch.ones(3,4)\n",
    "one_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8127f2d0-6737-457b-9b0f-e99858196ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# checking data type of tensors\n",
    "print(one_tensor.dtype)\n",
    "print(random_image_tensor.dtype)\n",
    "print(random_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcb3ef-2e7f-4ea0-8c4c-86ae4299992f",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensor-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17866412-dafc-487a-8edd-238973d3a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.range()\n",
    "torch.arange(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91c2a9fa-5a21-4727-b303-5b065ab3cd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using start end and step with arange\n",
    "one_to_ten = torch.arange(start=1, end=11, step= 1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8336740-6d1c-4bd3-9d42-1f770ac03a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ae9ef2a-92e0-411f-a366-6548bf9e575f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors_like\n",
    "ten_zeros = torch.zeros_like(input= one_to_ten)     #Check you can see that this new tensor is having the same size as one_to_ten tensor\n",
    "ten_zeros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af3d587c-229f-45e1-9dce-ea74fb21cab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,   3,   5,   7,   9,  11,  13,  15,  17,  19,  21,  23,  25,  27,\n",
       "         29,  31,  33,  35,  37,  39,  41,  43,  45,  47,  49,  51,  53,  55,\n",
       "         57,  59,  61,  63,  65,  67,  69,  71,  73,  75,  77,  79,  81,  83,\n",
       "         85,  87,  89,  91,  93,  95,  97,  99, 101, 103, 105, 107, 109, 111,\n",
       "        113, 115, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135, 137, 139,\n",
       "        141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163, 165, 167,\n",
       "        169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191, 193, 195,\n",
       "        197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219, 221, 223,\n",
       "        225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247, 249, 251,\n",
       "        253, 255, 257, 259, 261, 263, 265, 267, 269, 271, 273, 275, 277, 279,\n",
       "        281, 283, 285, 287, 289, 291, 293, 295, 297, 299, 301, 303, 305, 307,\n",
       "        309, 311, 313, 315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335,\n",
       "        337, 339, 341, 343, 345, 347, 349, 351, 353, 355, 357, 359, 361, 363,\n",
       "        365, 367, 369, 371, 373, 375, 377, 379, 381, 383, 385, 387, 389, 391,\n",
       "        393, 395, 397, 399, 401, 403, 405, 407, 409, 411, 413, 415, 417, 419,\n",
       "        421, 423, 425, 427, 429, 431, 433, 435, 437, 439, 441, 443, 445, 447,\n",
       "        449, 451, 453, 455, 457, 459, 461, 463, 465, 467, 469, 471, 473, 475,\n",
       "        477, 479, 481, 483, 485, 487, 489, 491, 493, 495, 497, 499, 501, 503,\n",
       "        505, 507, 509, 511, 513, 515, 517, 519, 521, 523, 525, 527, 529, 531,\n",
       "        533, 535, 537, 539, 541, 543, 545, 547, 549, 551, 553, 555, 557, 559,\n",
       "        561, 563, 565, 567, 569, 571, 573, 575, 577, 579, 581, 583, 585, 587,\n",
       "        589, 591, 593, 595, 597, 599, 601, 603, 605, 607, 609, 611, 613, 615,\n",
       "        617, 619, 621, 623, 625, 627, 629, 631, 633, 635, 637, 639, 641, 643,\n",
       "        645, 647, 649, 651, 653, 655, 657, 659, 661, 663, 665, 667, 669, 671,\n",
       "        673, 675, 677, 679, 681, 683, 685, 687, 689, 691, 693, 695, 697, 699,\n",
       "        701, 703, 705, 707, 709, 711, 713, 715, 717, 719, 721, 723, 725, 727,\n",
       "        729, 731, 733, 735, 737, 739, 741, 743, 745, 747, 749, 751, 753, 755,\n",
       "        757, 759, 761, 763, 765, 767, 769, 771, 773, 775, 777, 779, 781, 783,\n",
       "        785, 787, 789, 791, 793, 795, 797, 799, 801, 803, 805, 807, 809, 811,\n",
       "        813, 815, 817, 819, 821, 823, 825, 827, 829, 831, 833, 835, 837, 839,\n",
       "        841, 843, 845, 847, 849, 851, 853, 855, 857, 859, 861, 863, 865, 867,\n",
       "        869, 871, 873, 875, 877, 879, 881, 883, 885, 887, 889, 891, 893, 895,\n",
       "        897, 899, 901, 903, 905, 907, 909, 911, 913, 915, 917, 919, 921, 923,\n",
       "        925, 927, 929, 931, 933, 935, 937, 939, 941, 943, 945, 947, 949, 951,\n",
       "        953, 955, 957, 959, 961, 963, 965, 967, 969, 971, 973, 975, 977, 979,\n",
       "        981, 983, 985, 987, 989, 991, 993, 995, 997, 999])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Practice of tensor_like and arange()\n",
    "\n",
    "one_to_thousand = torch.arange(start=1, end=1001, step=2)\n",
    "one_to_thousand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dd37511-aa20-46a3-b4fd-b22e5da686c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_thousand.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da086e8e-58da-483f-84a7-142b58a5fb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now creating a tensor of same size as one_to_thousand but of zeros\n",
    "one_to_thousand_zeros = torch.zeros_like(input=one_to_thousand)\n",
    "one_to_thousand_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6912ca7f-41da-42da-a57b-671dbc0dc86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_thousand_zeros.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc4ac9-ef31-4a9d-ad96-ddc8fa0985d8",
   "metadata": {},
   "source": [
    "# TENSOR DATA TYPES\n",
    "**Note:** Tensor datatypes is one of the 3 big issues with Pytorch and Deep learning\n",
    "1. Tensors not right datatypes\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e831a9ea-c20e-414c-8020-d268c8c4a762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1000, 34.0000,  5.0000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float32 tensor\n",
    "float_32_tensor = torch.tensor([0.1,34,5], dtype=torch.float32, device=None,requires_grad=False)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea172228-c162-4ea9-9766-14e0704c6d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7565ab2-38e7-4016-831b-9738b6ffd060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1000, 34.0000,  5.0000], dtype=torch.float16)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now changing data type of float32tensor into float16tensor\n",
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e539c3ba-5b13-4c32-9dd8-2c5ef6da36c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.9976e-03, 1.1560e+03, 2.5000e+01])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see if we can multiple two different data type tensors\n",
    "(float_16_tensor*float_32_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b255553-92b2-4f50-b9af-defc45696ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 4], dtype=torch.int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create integer type tensor\n",
    "int_32_tensor = torch.tensor([3,2,4], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e6c0661-eb67-4b5d-9b5f-3af79bb2ecd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2998, 68.0000, 20.0000], dtype=torch.float16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now check if we can multiply float and int\n",
    "float_16_tensor*int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253bab98-81ce-4923-87cc-45f78c81a030",
   "metadata": {},
   "source": [
    "### Getting information from tensors\n",
    "1. Tensors not right datatypes - To get datatype from a tensor, can use tensor.dtype\n",
    "2. Tensors not right shape - To get shape from tensor, can use tensor.shape\n",
    "3. Tensors not on the right device - To get device from tensor, can use tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8197dc20-1c7d-4a0f-84b6-e9eda6a6c12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9253, 0.4396, 0.5016, 0.1227],\n",
       "        [0.7058, 0.8060, 0.4502, 0.6230],\n",
       "        [0.9177, 0.2869, 0.2333, 0.1330]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72c69282-5458-48cc-92ac-4f8266040274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type of somme_tensor:  torch.float32\n",
      "Shape of some_tensor: torch.Size([3, 4])\n",
      "Device of some_tensor: cpu\n",
      "Size of some_tensor: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some_tensor\n",
    "print(f\"Data Type of somme_tensor:  {some_tensor.dtype}\")\n",
    "print(f\"Shape of some_tensor: {some_tensor.shape}\")\n",
    "print(f\"Device of some_tensor: {some_tensor.device}\")\n",
    "print(f\"Size of some_tensor: {some_tensor.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41aa3a5-058e-41a2-a43b-5e66a154bee6",
   "metadata": {},
   "source": [
    "### Manipulating tensors (Tensor Operations)\n",
    "\n",
    "A link which i found useful: https://medium.com/@tushartripathi301997/pytorch-arithmetic-operations-and-matrix-ultiplication-49e14a624964\n",
    "\n",
    "Tensor Operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element wise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd4168da-a9c4-4525-a7f8-16930b36ffb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensor\n",
    "tensor =  torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04d5d95c-988f-4458-9798-f98d117ca3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10\n",
    "tensor*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6b782a1-f14f-47b1-8e97-3f9d8426bbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction tensor by 10\n",
    "tensor-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a447ca5a-0a38-43b3-a911-ba7dc0a09139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out Pytorch in-built functions\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "388b050b-3141-409b-91ee-2b713e484857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17db91-0fa7-4c1e-b4b2-6da13ccf3064",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "Two main ways of performing multiplication in neural netwroks and deep learning:\n",
    "* Element wise\n",
    "* Matrix Multiplication (Dot Product)\n",
    "<br>**More information on matrix multiplication:** https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
    "<br> There are two main rules that performing matrix multiplication needs to be satisfied:\n",
    "1. The **Inner Dimension** must match:\n",
    "* `(3,2) @ (3,2)` won't work\n",
    "* `(2,3) @ (3,2)` will work\n",
    "* `(3,2) @ (2,3)` will work\n",
    "\n",
    "2. The resulting matrix has the shape of **Outer Dimension** so:\n",
    "* `(2,3) @ (3,2)` -> `(2,3) @ (3,2)`\n",
    "* `(3,2) @ (2,3)` -> `(3,3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efa5ff64-823d-4124-8e0b-e6a965063e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "print(tensor, \"*\" ,tensor)\n",
    "print(f\"Equals: {tensor*tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a026079b-5659-4890-8903-66d366cdde47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34d794ee-6609-44dc-9e78-3909dd19179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i]*tensor[i]\n",
    "print(value) # checking the time used to solve matrix multplication by for loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d535be73-356d-4c0f-88a4-59e0bb3cd080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor) # checking time to solve matrix multiplication by using pytorch vectorization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28241e3b-c3c8-4880-8dc8-725405d7c360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9185, 0.8526],\n",
       "         [0.3778, 0.0887]],\n",
       "\n",
       "        [[0.4744, 0.8913],\n",
       "         [0.1118, 0.0188]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Practicing by creating a big tensor and multiplying them\n",
    "example_tensor1= torch.rand(2,2,2)\n",
    "example_tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce4c620f-9e2e-45ac-8a6f-d0c0303cc3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8337, 0.7001],\n",
       "         [0.5592, 0.7928]],\n",
       "\n",
       "        [[0.2657, 0.3204],\n",
       "         [0.6983, 0.8918]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tensor2= torch.rand(2,2,2)\n",
    "example_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "462383f6-3418-40da-8b8b-68ada118ab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 986 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value_example = 0\n",
    "for i in range(len(example_tensor1)):\n",
    "    value_example += value_example *example_tensor1[i]*example_tensor2[i]\n",
    "print(value_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a559c34-1c0a-4958-982d-2cda1ce728e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 14.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2426, 1.3189],\n",
       "         [0.3646, 0.3348]],\n",
       "\n",
       "        [[0.7484, 0.9469],\n",
       "         [0.0428, 0.0526]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(example_tensor1, example_tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e1068-a330-46c4-b656-c626f98cb69f",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning is shape error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d94895b-6815-49e6-8d72-c09ddbb5dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]]) #shape is (3x2)\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]]) #shape is (3x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f0dd2a9-ae6b-4673-a4e6-88cf737c9a75",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#torch.mm(tensor_A, tensor_B) # torch.mm(,) is same as toch.matmul(,)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "#torch.mm(tensor_A, tensor_B) # torch.mm(,) is same as toch.matmul(,)\n",
    "torch.matmul(tensor_A, tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143efdc-181d-417d-8bc4-5216fdd84187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the shape of tensors and find out why we are not able to multiply the tensors\n",
    "tensor_A.shape , tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bd5e90-4980-4dff-9e6c-5d3013d60817",
   "metadata": {},
   "source": [
    "to fix our tensor shape issues, we can manipulate the shape of one our tensors using a **TRANSPOSE**\n",
    "A **Transpose** switches the axes or dimensions of a given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00162f9-640d-46a9-854b-95a2ef42caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_B.T # .T makes is transpose and turned it into (2x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a5c2e-5dda-4dc1-8cae-d47bd191a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the transpose shape\n",
    "tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578605d-643e-4957-873f-b186d9aacd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can multiply\n",
    "print(torch.matmul(tensor_A,tensor_B.T))\n",
    "print(f\"Shape of new Matrix: {torch.matmul(tensor_A,tensor_B.T).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f96f97-9ade-4c56-a87a-66f5c908e9a4",
   "metadata": {},
   "source": [
    "### Finding the min, max, mea, sum, etc (Tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec4b19-59b6-426f-a5b1-7e556b3ca357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x\n",
    "print(f\"x data type: {x.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cb192-79a3-4c3d-a92f-ea06fea9bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2762912-2c62-432a-aa89-d6d336313627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec7b77-c421-49ee-9cc4-2e808689170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean NOTE: We have to use Float type in mean so to change data type you can use.type() function\n",
    "# **E.g: x.type(torch.float64)**\n",
    "\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27ea6d-6ae4-4f0b-9f10-5c30b6f72fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df361b14-8daa-44ea-a5de-51f5211d45e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the position in tensor that has the minimum value with argmin() -> resturns the index of the min value in the tensor\n",
    "torch.argmin(x),x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f58bde-a1ea-4122-a0da-26dceb27f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the position in tensor that has the maximum value with argmax() -> resturns the index of the max value in the tensor\n",
    "torch.argmax(x),x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35fc445-4863-4bae-8b1f-253c9bfbe7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see what is the min and max value that we got on the index \n",
    "x[0] , x[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf357287-0bc3-47b9-bbc2-6fd011819d04",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "* **Reshaping** - Reshapes an input tensor to a defined shape\n",
    "* **View** - Return a view of an input tensor of certain shape but keep the memory as the original tensor\n",
    "* **Stacking** - Combine multiple tensors on top of each other(eg: vstack) or side-by-side(eg:hstack)\n",
    "* **Squeezing** - Removes all `1` dimensions from a tensor\n",
    "* **Unsqueeze** - add `1` dimension to a target tensor\n",
    "* **Permute** - Return a view of the input with dimensions permuted(swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea66ee-7d31-429d-b710-36e90760a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a tensor\n",
    "y = torch.arange(0,100,2.5)\n",
    "y, y.shape, y.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2f147-ec75-49a1-a207-70b101ccd033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an extra dimension\n",
    "# y_reshaped = y.reshape(2,40)  # will give error because the tensor size is 40 and if we create from 2 to 40 it wil be 39\n",
    "y_reshaped = y.reshape(1,40)\n",
    "# y_reshaped = y.reshape(40,1) # will also but the shape will change to (40,1)\n",
    "y_reshaped,y_reshaped.shape, y_reshaped.dim() #we can see that the dimension of the tensor has now changed to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e84d060-70f4-45fe-94b9-252fa311d68d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Change the view\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m z = \u001b[43my\u001b[49m.view(\u001b[32m1\u001b[39m,\u001b[32m40\u001b[39m) \u001b[38;5;66;03m# it works similar to the .reshape() but ther is a small difference\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# z = y.view(40,1)\u001b[39;00m\n\u001b[32m      4\u001b[39m z, z.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# Change the view\n",
    "z = y.view(1,40) # it works similar to the .reshape() but ther is a small difference\n",
    "# z = y.view(40,1)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18eb35-750a-4d24-9562-6d632776d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changeing Z changes X (because a view of a tensor shares the same memory as the original input)\n",
    "# lets try to change value of tensor z and check if y changes or not\n",
    "print(f\"Value of z at second position: {z[0, 1]} and Value of y at second position: {y[1]}\")\n",
    "print(\"Now changing the value of z = 5 \")\n",
    "z[0,1] = 5\n",
    "print(f\"Value of z at second position: {z[0, 1]} and Value of y at second position: {y[1]}\") # it is changed now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4319e9b9-92ab-4931-a05d-1a1ff64b77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack tensors on top of each other\n",
    "y_stacked = torch.stack([y,y,y,y], dim=0) # you can change dimension depending upon the dimension of Y\n",
    "y_stacked, y_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "238c229e-64c9-49f1-96b5-63d11eefde78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t tensor: tensor([[[0.2121, 0.7155]],\n",
      "\n",
      "        [[0.5486, 0.2521]]]), t-tensor shape: torch.Size([2, 1, 2]) , t_squeezed tensor: tensor([[0.2121, 0.7155],\n",
      "        [0.5486, 0.2521]]), t_squeezed tensor shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Squeezing the tensors - it removes the single dimension in the tensor \n",
    "# Creating the tensor in which it is having 1 dimension\n",
    "t = torch.rand(2,1,2)\n",
    "t_squeeze = t.squeeze() \n",
    "print(f\"t tensor: {t}, t-tensor shape: {t.shape} , t_squeezed tensor: {t_squeeze}, t_squeezed tensor shape: {t_squeeze.shape}\")\n",
    "\n",
    "# You can see that the 1 dimension is removed from the tensor and new shape is (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6b87b09-47a3-4c70-b482-6af2817c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_squeezed tensor: tensor([[0.2121, 0.7155],\n",
      "        [0.5486, 0.2521]]), t_squeezed tensor shape: torch.Size([2, 2]) , t_unsqueezed tensor: tensor([[[0.2121, 0.7155],\n",
      "         [0.5486, 0.2521]]]), t_unsqueezed tensor shape: torch.Size([1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Unsqueezing the tensor - it adds a single dimension to the tensor\n",
    "t_unsqueeze = t_squeeze.unsqueeze(dim=0)  # You can change the dimension \n",
    "print(f\"t_squeezed tensor: {t_squeeze}, t_squeezed tensor shape: {t_squeeze.shape} , t_unsqueezed tensor: {t_unsqueeze}, t_unsqueezed tensor shape: {t_unsqueeze.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d023055-9607-4985-b434-578bae8cb0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[[0.1636, 0.7039, 0.4157],\n",
      "         [0.3787, 0.6732, 0.3655],\n",
      "         [0.0819, 0.7862, 0.3969],\n",
      "         ...,\n",
      "         [0.9061, 0.1425, 0.3961],\n",
      "         [0.7800, 0.1431, 0.2416],\n",
      "         [0.3247, 0.5223, 0.5497]],\n",
      "\n",
      "        [[0.1685, 0.6395, 0.5157],\n",
      "         [0.3427, 0.0168, 0.9115],\n",
      "         [0.8503, 0.5320, 0.0290],\n",
      "         ...,\n",
      "         [0.2460, 0.2511, 0.2377],\n",
      "         [0.3604, 0.7498, 0.7533],\n",
      "         [0.3107, 0.1610, 0.5602]],\n",
      "\n",
      "        [[0.7114, 0.9298, 0.3643],\n",
      "         [0.6169, 0.1749, 0.5478],\n",
      "         [0.5821, 0.8768, 0.6738],\n",
      "         ...,\n",
      "         [0.5274, 0.2773, 0.7424],\n",
      "         [0.3152, 0.5677, 0.2424],\n",
      "         [0.3469, 0.0969, 0.7799]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5741, 0.8579, 0.5985],\n",
      "         [0.9494, 0.0553, 0.4140],\n",
      "         [0.7485, 0.5476, 0.6991],\n",
      "         ...,\n",
      "         [0.5281, 0.1279, 0.3822],\n",
      "         [0.4884, 0.8641, 0.7906],\n",
      "         [0.4446, 0.2353, 0.1669]],\n",
      "\n",
      "        [[0.2959, 0.7244, 0.3860],\n",
      "         [0.8284, 0.4901, 0.5850],\n",
      "         [0.0683, 0.4890, 0.8341],\n",
      "         ...,\n",
      "         [0.7843, 0.7669, 0.6555],\n",
      "         [0.1964, 0.5511, 0.9072],\n",
      "         [0.9501, 0.9918, 0.7622]],\n",
      "\n",
      "        [[0.4618, 0.6858, 0.1706],\n",
      "         [0.3288, 0.0649, 0.7754],\n",
      "         [0.5819, 0.1374, 0.2185],\n",
      "         ...,\n",
      "         [0.1622, 0.9344, 0.3851],\n",
      "         [0.3367, 0.8041, 0.5208],\n",
      "         [0.5500, 0.3127, 0.9729]]]) ,Previous tensor shape: torch.Size([224, 224, 3])\n",
      "new tensor: tensor([[[0.1636, 0.3787, 0.0819,  ..., 0.9061, 0.7800, 0.3247],\n",
      "         [0.1685, 0.3427, 0.8503,  ..., 0.2460, 0.3604, 0.3107],\n",
      "         [0.7114, 0.6169, 0.5821,  ..., 0.5274, 0.3152, 0.3469],\n",
      "         ...,\n",
      "         [0.5741, 0.9494, 0.7485,  ..., 0.5281, 0.4884, 0.4446],\n",
      "         [0.2959, 0.8284, 0.0683,  ..., 0.7843, 0.1964, 0.9501],\n",
      "         [0.4618, 0.3288, 0.5819,  ..., 0.1622, 0.3367, 0.5500]],\n",
      "\n",
      "        [[0.7039, 0.6732, 0.7862,  ..., 0.1425, 0.1431, 0.5223],\n",
      "         [0.6395, 0.0168, 0.5320,  ..., 0.2511, 0.7498, 0.1610],\n",
      "         [0.9298, 0.1749, 0.8768,  ..., 0.2773, 0.5677, 0.0969],\n",
      "         ...,\n",
      "         [0.8579, 0.0553, 0.5476,  ..., 0.1279, 0.8641, 0.2353],\n",
      "         [0.7244, 0.4901, 0.4890,  ..., 0.7669, 0.5511, 0.9918],\n",
      "         [0.6858, 0.0649, 0.1374,  ..., 0.9344, 0.8041, 0.3127]],\n",
      "\n",
      "        [[0.4157, 0.3655, 0.3969,  ..., 0.3961, 0.2416, 0.5497],\n",
      "         [0.5157, 0.9115, 0.0290,  ..., 0.2377, 0.7533, 0.5602],\n",
      "         [0.3643, 0.5478, 0.6738,  ..., 0.7424, 0.2424, 0.7799],\n",
      "         ...,\n",
      "         [0.5985, 0.4140, 0.6991,  ..., 0.3822, 0.7906, 0.1669],\n",
      "         [0.3860, 0.5850, 0.8341,  ..., 0.6555, 0.9072, 0.7622],\n",
      "         [0.1706, 0.7754, 0.2185,  ..., 0.3851, 0.5208, 0.9729]]]) ,new tensor shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Permuting the tensor - Rearrange the tensor in a specified order. torch.permute and it works like the .view()\n",
    "x_original = torch.rand(size=(224, 224,3))  # [height, width, colour channels]\n",
    "print(f\"Previous tensor: {x_original} ,Previous tensor shape: {x_original.shape}\")\n",
    "# permute the original tensor to rearrange the axis (or dim) order e.g: [color channel, height, width]\n",
    "x_permute = x_original.permute(2,0,1)\n",
    "print(f\"new tensor: {x_permute} ,new tensor shape: {x_permute.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b7be80-485b-410d-be02-b4f0d738e06e",
   "metadata": {},
   "source": [
    "## Indexing (Selecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0c00b53-e028-4b62-95b2-11513cecf6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1,  2,  3],\n",
       "          [ 4,  5,  6],\n",
       "          [ 7,  8,  9]],\n",
       " \n",
       "         [[10, 11, 12],\n",
       "          [13, 14, 15],\n",
       "          [16, 17, 18]]]),\n",
       " torch.Size([2, 3, 3]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Tensor\n",
    "x = torch.arange(1,19).reshape(2,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7ba327b7-4e8a-40e0-b24b-4e49257fcec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets index on our new tensor\n",
    "x[0][1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29dad56-6166-4216-ae6a-fd0772630df9",
   "metadata": {},
   "source": [
    "### Pytorch Tensors and Numpy \n",
    "\n",
    "Numpy is a popular scientific Python numerical computing Library. https://numpy.org/\n",
    "and becuse of this, PyTorch has functionality to interact with it.\n",
    "*Data in Numpy,want in PyTorch tensor -> ``torch.from_numpy(ndarray)`\n",
    "PyTorch tensor -> Numpy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4cc99f68-c024-456a-b4a9-a477bd5fa385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # importing numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dd06dbb0-a885-4cf8-87d1-cadb2375aac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1.0,8.0)\n",
    "tensor = torch.from_numpy(array) # Warning: When converting from Numpy -> PyTorch, PyTorch reflects numpy´s default dtype of float64 unless specified otherwise\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5455af07-7bb6-49b8-b9c4-082366f9e90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1670cfb2-f5e2-4743-bf4f-49777020e0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b72159a-dd4f-475f-a73b-2cb0632a8140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we change anything in array  will it be changed in tensor as well ?\n",
    "array = array  + 1\n",
    "array, tensor\n",
    "# NOTE: It didn´t change anything in tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a6b35d9-b96a-4ff7-a0fe-7d2625f861d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " torch.Size([2, 8]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "tensor = torch.zeros(2,8) # using .zero() or ones() will make a tensor of zeros or one\n",
    "tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3560b1cf-65ee-4b69-8509-e176e6f4cd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32),\n",
       " (2, 8))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now changing tensor to Numpy\n",
    "numpy_tensor = tensor.numpy()\n",
    "numpy_tensor, numpy_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de6dddf6-9484-44b9-8dbf-291aef40996c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2., 2., 2.]]),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happens to `numpy_tensor`?\n",
    "tensor = tensor +2\n",
    "tensor, numpy_tensor\n",
    "# Result shows it doesn´t share memory as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238839e-0105-4372-98c2-f29861eec0db",
   "metadata": {},
   "source": [
    "## Reproducibilty (Trying to take random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "<br>`Start with random number -> tensors operations -> update random numbbers to try and make them of the data -> again -> again -> again..`\n",
    "<br> To reduce the randomnessin neural networks and PyTorch come the concept of a **random seed**  https://docs.pytorch.org/docs/stable/notes/randomness.html\n",
    "<br> Essentially what the random seed does is **Flavour** the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "37a3c794-9c7e-4519-8367-93814131bec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0718, 0.5035, 0.9528, 0.0226],\n",
      "        [0.6422, 0.2827, 0.5259, 0.7548],\n",
      "        [0.9558, 0.7492, 0.7992, 0.6982]])\n",
      "tensor([[0.0044, 0.6138, 0.9152, 0.6776],\n",
      "        [0.7342, 0.1554, 0.6742, 0.4076],\n",
      "        [0.2497, 0.0465, 0.3228, 0.1256]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B) #checking if the values are equal in both random tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "46368aae-0f7f-4bad-ab61-20bce833b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4581, 0.4829, 0.3125, 0.6150],\n",
      "        [0.2139, 0.4118, 0.6938, 0.9693],\n",
      "        [0.6178, 0.3304, 0.5479, 0.4440]])\n",
      "tensor([[0.4581, 0.4829, 0.3125, 0.6150],\n",
      "        [0.2139, 0.4118, 0.6938, 0.9693],\n",
      "        [0.6178, 0.3304, 0.5479, 0.4440]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Lets make some random but reproducinle tensors\n",
    "\n",
    "# Set the random seed\n",
    "random_seed = 10  # change the value of random_seed if you want to change the values in random tensors\n",
    "\n",
    "torch.manual_seed(random_seed) # You have to feed rendom_seed value in torch.manual_seed(random_seed)\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(random_seed)  # You have to call this function everytime you want to create a new random tensor with reproducibilty\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_C) \n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D) #checking if the values are equal in both random tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8e1d8-87e6-48ec-bad4-929e942f2c68",
   "metadata": {},
   "source": [
    "### Running Tensors and PyTorch Objects on GPU´s (Making faster computations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2c6ae-08f2-4b81-9ad8-93253bf1ef8e",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU\n",
    "1. `Use your own GPU - Takes a little bit of setup and requires the investment on GPU`\n",
    "2. `Use cloud computing - GCP, AWS, AZURE, these services allow you to rent computers on the cloud and access them`\n",
    "\n",
    "For 1 and 2 PyTorch + GPU driver(CUDA) takes a little bit of setting up, to do this. refer to PyTorch setup documentation. https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa3533bd-0a91-4239-9b18-874822775ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun  7 03:11:47 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.07                 Driver Version: 566.07         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   48C    P8              3W /   80W |    1365MiB /   8188MiB |     29%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A       532    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A      2580    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A      3620    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      6768    C+G   ...1efjmfn5c\\Build\\Plugins\\mpv\\mpv.exe      N/A      |\n",
      "|    0   N/A  N/A      9260    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A      9724    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14064    C+G   ...pdnekdrzrea0\\XboxGameBarSpotify.exe      N/A      |\n",
      "|    0   N/A  N/A     16264    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     19072    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19516    C+G   ...4__8wekyb3d8bbwe\\EdgeGameAssist.exe      N/A      |\n",
      "|    0   N/A  N/A     20420    C+G   ...on\\136.0.3240.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     21152    C+G   ...1efjmfn5c\\Build\\Plugins\\mpv\\mpv.exe      N/A      |\n",
      "|    0   N/A  N/A     22388    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     22492    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     23356    C+G   ...ram Files (x86)\\AnyDesk\\AnyDesk.exe      N/A      |\n",
      "|    0   N/A  N/A     28472    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     28628    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     30556    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     31324    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     32500    C+G   ...x64__swvc1efjmfn5c\\Build\\Lively.exe      N/A      |\n",
      "|    0   N/A  N/A     32604    C+G   ...on\\136.0.3240.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     33084    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     33092    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A     34484    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     36756    C+G   ..._x64__cw5n1h2txyewy\\WidgetBoard.exe      N/A      |\n",
      "|    0   N/A  N/A     38880    C+G   ...__8wekyb3d8bbwe\\Microsoft.Notes.exe      N/A      |\n",
      "|    0   N/A  N/A     39524    C+G   ...ecurityApp\\MicrosoftSecurityApp.exe      N/A      |\n",
      "|    0   N/A  N/A     39992    C+G   ...ve\\Discord\\app-1.0.9194\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     40552    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74623a12-cc29-495a-aac5-bdbf0e0b697b",
   "metadata": {},
   "source": [
    "### Check for GPU access with PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b278896e-47a2-402e-8a52-f87a8fcb88ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for GPU access with PyTorch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e3f771c-93cc-46a9-9662-5d69fdf1b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36ba52-e8a0-4a29-9ba6-25a87a300f26",
   "metadata": {},
   "source": [
    "For PyTorch since it´s capable of running compute on the GPU or CPU, it´s best practice is to setup device agnostic code: https://docs.pytorch.org/docs/stable/notes/cuda.html#best-practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4d18c02-ccdc-4f90-8da6-5ba32b7a957f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1bccc44c-7519-4e05-87ab-825a9e46549b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "febe90f1-434b-43ff-97e9-a0ed2a05e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('GPU name:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"no GPU available\")\n",
    "# print('GPU name:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"no GPU available\")\n",
    "# !nvidia-smi\n",
    "# import torch\n",
    "# print(\"PyTorch version:\", torch.__version__)\n",
    "# print(\"CUDA in PyTorch:\", torch.version.cuda)\n",
    "# print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "# import sys\n",
    "# print(sys.version)\n",
    "# import sys\n",
    "# print(sys.executable)\n",
    "# print(sys.version)\n",
    "\n",
    "## to check the GPU is being used or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f2dfeb-cc47-4cfb-9821-88a673a6dd0d",
   "metadata": {},
   "source": [
    "## 3. Putting tensors (and Models) on the GPU\n",
    "The reason is we want our tensors/models on the GPU is because usinng a GPU results in faster computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc073642-f970-4e8e-b87d-9f8e851012af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    " # Create a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1,2,3], device =\"cpu\" )  # default is cpu\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb9aafc8-cc5f-4e16-8d31-f6b96ace1107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc7ef3-26eb-4bb0-b8b0-276ddd1ca84e",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "60a86e77-e746-4693-8490-4e66c63d040b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[90]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# If tensor is on GPU, can´t transform it to Numpy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtensor_on_gpu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can´t transform it to Numpy\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3e6ab1ec-ccd8-4a48-8793-daf794338609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to convert tensor to CPU . So we will use tensor.cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "82668c71-92ab-4781-b5e5-291cd2835a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix the GPU tensor with Numpy issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ca84f-a8be-4e5f-b150-3d4ae321b832",
   "metadata": {},
   "source": [
    "### EXERCISES AND EXTRA CURRICULUM\n",
    "<br> see the link for exercises till we have done in the notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b344e61b-f507-4581-89bb-705cb4332a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7041, 0.5573, 0.6959, 0.9849, 0.2924, 0.4823, 0.6150],\n",
       "        [0.4967, 0.4521, 0.0575, 0.0687, 0.0501, 0.0108, 0.0343],\n",
       "        [0.1212, 0.0490, 0.0310, 0.7192, 0.8067, 0.8379, 0.7694],\n",
       "        [0.6694, 0.7203, 0.2235, 0.9502, 0.4655, 0.9314, 0.6533],\n",
       "        [0.8914, 0.8988, 0.3955, 0.3546, 0.5752, 0.4787, 0.5782],\n",
       "        [0.7536, 0.1093, 0.4771, 0.1076, 0.9829, 0.1483, 0.5956],\n",
       "        [0.3634, 0.7842, 0.5017, 0.4497, 0.8660, 0.9567, 0.1371]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with shape (7, 7).\n",
    "ex_tensor = torch.rand(7,7)\n",
    "ex_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a513d973-29dd-47d4-bf66-61238044768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1734],\n",
       "        [0.3989],\n",
       "        [2.0813],\n",
       "        [2.4314],\n",
       "        [2.0367],\n",
       "        [1.6660],\n",
       "        [2.6003]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7) (hint: you may have to transpose the second tensor).\n",
    "ex_tensor2 = torch.rand(1,7)\n",
    "ex_tensor2\n",
    "# now multiplying both tensors\n",
    "mul_ten = torch.matmul(ex_tensor,ex_tensor2.t())\n",
    "mul_ten # multiplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f5a3d8c9-c1d8-43fd-befa-ba7af789359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901],\n",
      "        [0.8964, 0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n",
      "        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823, 0.6816],\n",
      "        [0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527, 0.0362],\n",
      "        [0.1852, 0.3734, 0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
      "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
      "        [0.5846, 0.0332, 0.1387, 0.2422, 0.8155, 0.7932, 0.2783]])\n",
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.5985],\n",
       "        [1.1173],\n",
       "        [1.2741],\n",
       "        [1.6838],\n",
       "        [0.8279],\n",
       "        [1.0347],\n",
       "        [1.2498]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the random seed to 0 and do exercises 2 & 3 over again.\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "ex_tensor = torch.rand(7,7)\n",
    "print(ex_tensor) \n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "ex_tensor2 = torch.rand(1,7)\n",
    "print(ex_tensor2)\n",
    "\n",
    "# now multiplying both the tensors \n",
    "mul_ten_rand =torch.matmul(ex_tensor,ex_tensor2.t())\n",
    "mul_ten_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a13812-fb8e-49b0-8f5c-67b677645891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73484e86-67b5-4186-8976-7c09e22d5cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3719d5c1-42ad-49a7-ab59-a8465c4c99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete other questions as well CURRENTLY I AM MOVING TO THE TUTORIAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0793cf00-1f1a-417f-9fba-8c60eaf10641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a67e67-04d7-4886-80e1-1d5becb13312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
